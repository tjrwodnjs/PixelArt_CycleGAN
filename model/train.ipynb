{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from manual_diff_augment import DiffAugment, rand_brightness, rand_cutout, rand_contrast, rand_saturation, make_rgb_to_gray, make_rgb_to_black\n",
    "import dezero\n",
    "from dezero import cuda\n",
    "import dezero.functions as F\n",
    "import dezero.layers as L\n",
    "from dezero import DataLoader\n",
    "from dezero.models import Sequential\n",
    "from dezero.optimizers import Adam\n",
    "use_gpu = cuda.gpu_enable\n",
    "print(use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = np.load('8bit_characters_50x50.npz')\n",
    "# extract the first array\n",
    "data = dict_data['arr_0']\n",
    "sample_data = data[0:32]\n",
    "data_with_label = []\n",
    "for i in range(len(data)):\n",
    "    reshaped = np.transpose(data[i], (2, 0, 1))\n",
    "    data_with_label.append((reshaped, i))\n",
    "dataloader = DataLoader(data_with_label, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(701, 50, 50, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight(dis, gen,):\n",
    "    # Input dummy data to initialize weights\n",
    "    batch_size = 1\n",
    "    z = np.random.rand(batch_size, 100, 1, 1)\n",
    "    fake_images = gen(z)\n",
    "    dis(fake_images)\n",
    "\n",
    "    for l in dis.layers + gen.layers:\n",
    "        classname = l.__class__.__name__\n",
    "        if classname.lower() in ('conv2d', 'linear', 'deconv2d'):\n",
    "            l.W.data = 0.02 * np.random.randn(*l.W.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Sequential(\n",
    "    L.Deconv2d(in_channels=100, out_channels=512, kernel_size=5, stride=2, pad=0, nobias=True),\n",
    "    L.BatchNorm(),\n",
    "    F.relu,\n",
    "    \n",
    "    L.Deconv2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, pad=0, nobias=True),\n",
    "    L.BatchNorm(),\n",
    "    F.relu,\n",
    "\n",
    "    L.Deconv2d(in_channels=256, out_channels=128, kernel_size=5, stride=2, pad=1, nobias=True),\n",
    "    L.BatchNorm(),\n",
    "    F.relu,\n",
    "\n",
    "    L.Deconv2d(in_channels=128, out_channels=3, kernel_size=4, stride=2, pad=1, nobias=True),\n",
    "    F.tanh,\n",
    ")\n",
    "\n",
    "dis = Sequential(\n",
    "    L.Conv2d(in_channels=3, out_channels=32, kernel_size=4, stride=2, pad=1, nobias=True),\n",
    "    F.leaky_relu,\n",
    "\n",
    "    L.Conv2d(in_channels=32, out_channels=32*2, kernel_size=3, stride=2, pad=1, nobias=True),\n",
    "    L.BatchNorm(),\n",
    "    F.leaky_relu,\n",
    "\n",
    "    L.Conv2d(in_channels=32*2, out_channels=32*4, kernel_size=5, stride=2, pad=1, nobias=True),\n",
    "    L.BatchNorm(),\n",
    "    F.leaky_relu,\n",
    "\n",
    "    L.Conv2d(in_channels=32*4, out_channels=32*8, kernel_size=2, stride=2, pad=0, nobias=True),\n",
    "    L.BatchNorm(),\n",
    "    F.leaky_relu,\n",
    "\n",
    "    L.Conv2d(in_channels=32*8, out_channels=1, kernel_size=3, stride=1, pad=0, nobias=True),\n",
    "    F.sigmoid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_g = Adam(alpha=0.0002, beta1=0.5).setup(gen)\n",
    "opt_d = Adam(alpha=0.0002, beta1=0.5).setup(dis)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "init_weight(dis, gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    gen.to_gpu()\n",
    "    dis.to_gpu()\n",
    "    dataloader.to_gpu()\n",
    "    xp = cuda.cupy\n",
    "else:\n",
    "    xp = np\n",
    "\n",
    "label_real = xp.ones(batch_size).astype(int)\n",
    "label_fake = xp.zeros(batch_size).astype(int)\n",
    "test_z = xp.random.randn(32,100, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(epoch, loss):\n",
    "    with dezero.test_mode():\n",
    "        fake_images = gen(test_z)\n",
    "\n",
    "    img = cuda.as_numpy(fake_images.data)\n",
    "    img = (img + 1)/2\n",
    "    img = np.transpose(img, (0, 2, 3, 1))\n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "    columns = rows = 5\n",
    "    plt.title(f\"Training Images epoch: {epoch}, loss: {loss}\")\n",
    "    for i in range(1, columns*rows +1):\n",
    "        plt.axis(\"off\")\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        if i >= len(img):\n",
    "            break\n",
    "        plt.imshow(img[i])\n",
    "    plt.show()\n",
    "    plt.savefig(f'epoch_manual/gan_epoch:{epoch}.png')\n",
    "    plt.close()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_diff = 1 * 50 * 50 * batch_size\n",
    "\n",
    "max_epoch = 1000\n",
    "\n",
    "# policy = \"color,cutout\"\n",
    "\n",
    "def grayscale_diff(x,y):\n",
    "    gray_x = make_rgb_to_gray(x)\n",
    "    gray_y = make_rgb_to_gray(y)\n",
    "    squared = (gray_x - gray_y) ** 2\n",
    "    diff = squared.sum()\n",
    "    return diff\n",
    "\n",
    "def black_diff(x,y):\n",
    "    squared = (x - y) ** 2\n",
    "    black_x = make_rgb_to_black(x)\n",
    "    black_y = make_rgb_to_black(y)\n",
    "    squared = (black_x - black_y) ** 2\n",
    "    diff = squared.sum()\n",
    "    return diff\n",
    "\n",
    "\n",
    "print(black_diff(data[0:32], data[100:132]), ' this is diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    avg_loss_d = 0\n",
    "    avg_loss_g = 0\n",
    "    cnt = 0\n",
    "\n",
    "    for x, t in dataloader:\n",
    "        # print(x.shape, t.shape)\n",
    "        cnt += 1\n",
    "        if len(t) != batch_size:\n",
    "            continue\n",
    "\n",
    "        # Update discriminator\n",
    "        z = xp.random.randn(batch_size, 100, 1, 1).astype(np.float32)\n",
    "        # x = DiffAugment(x, policy=policy,is_cuda=use_gpu)\n",
    "        mod_x = rand_saturation(x, is_cuda=use_gpu)\n",
    "        mod_x = rand_contrast(mod_x, is_cuda=use_gpu)\n",
    "        mod_x = rand_cutout(mod_x, is_cuda=use_gpu)\n",
    "        fake_images = gen(z)\n",
    "        # fake_images = DiffAugment(fake_images, policy=policy, is_cuda=use_gpu)\n",
    "        mod_fake_images = rand_saturation(fake_images, is_cuda=use_gpu)\n",
    "        mod_fake_images = rand_contrast(mod_fake_images, is_cuda=use_gpu)\n",
    "        mod_fake_images = rand_cutout(mod_fake_images, is_cuda=use_gpu)\n",
    "        y_real = dis(mod_x)\n",
    "        y_fake = dis(mod_fake_images)\n",
    "\n",
    "\n",
    "        loss_d = F.binary_cross_entropy(y_real, label_real) +\\\n",
    "              F.binary_cross_entropy(y_fake, label_fake)\n",
    "        gen.cleargrads()\n",
    "        dis.cleargrads()\n",
    "        loss_d.backward()\n",
    "        opt_d.update()\n",
    "\n",
    "        # Update generator\n",
    "        y_fake = dis(mod_fake_images)\n",
    "        loss_g = F.binary_cross_entropy(y_fake, label_real)\n",
    "        gen.cleargrads()\n",
    "        dis.cleargrads()\n",
    "        loss_g.backward()\n",
    "        opt_g.update()\n",
    "\n",
    "        # Print loss & generate image\n",
    "        avg_loss_d += loss_d.data\n",
    "        avg_loss_g += loss_g.data\n",
    "        if epoch % 5 == 0 and cnt == 1:\n",
    "            epoch_dt = epoch + cnt / dataloader.max_iter\n",
    "            print('epoch: {:.2f}, loss_d: {:.4f}, loss_g: {:.4f}'.format(\n",
    "                epoch_dt, loss_d.data, loss_g.data))\n",
    "            generate_image(epoch, loss_g.data)\n",
    "            with dezero.test_mode():\n",
    "                test_diff = gen(xp.random.randn(32,100, 1, 1))\n",
    "\n",
    "            img_diff = cuda.as_numpy(test_diff.data)\n",
    "            img_diff = (img_diff + 1)/2\n",
    "            img_diff = np.transpose(img_diff, (0, 2, 3, 1))\n",
    "            # diff = 0\n",
    "            real_diff = cuda.as_numpy(x)\n",
    "            real_diff = (real_diff + 1)/2\n",
    "            real_diff = np.transpose(real_diff, (0, 2, 3, 1))\n",
    "            diff = black_diff(img_diff, real_diff)\n",
    "\n",
    "            print(\"black diff between real sample: \", diff)\n",
    "            if diff < min_diff and epoch > 150:\n",
    "                min_diff = diff\n",
    "                print('saving weights')\n",
    "                gen.save_weights(f'parameters_manual/gen_manual_epoch:{epoch}.npz')\n",
    "                gen.to_gpu()\n",
    "                # dis.save_weights(f'parameters_manual/dis_manual_epoch:{epoch}.npz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
